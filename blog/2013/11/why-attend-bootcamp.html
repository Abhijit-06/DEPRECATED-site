Here's a research workflow that we are all familiar with:
<ul>
  <li>A scientist collects some data and stores it on a machine that is occasionally 
      backed up by her department.</li>
  <li>She then writes or modifies a few small programs (which also reside on her machine) 
      to analyse that data, with assistance from Google/Stack Exchange and a helpful 
      colleague.</li> 
  <li>Once she has some results that look right (which alleviates her fear that there 
      might be bugs in her code), she writes them up and submits her paper. She might 
      include her data---a growing number of journals require this---but she probably 
      doesn't include her code.</li>
  <li>Time passes.</li>
  <li>The journal sends her reviews written anonymously by a handful of other people in 
      her field. She revises her paper to satisfy them, during which time she might also 
      modify the scripts she wrote earlier, and resubmits.</li>
  <li>More time passes.</li>
  <li>The paper is eventually published. It might include a link to an online copy of her 
      data, but the paper itself will be behind a paywall: only people who have personal 
      or institutional access will be able to read it.</li>
</ul>

If you read any research related blogs or scan the editorial sections of prominent 
journals like <em>Nature</em> or <em>Science</em>, you'll know that "open" and "web" are 
two of the major buzz words right now. In essence, this is because there are now a whole 
range of web based tools out there that make it possible for this workflow to be more 
collaborative, transparent, reproducible and reliable than ever before. All scientists 
would agree that these are much needed improvements, but most lack the requisite 
computing skills to fully participate in this "open science" revolution. It is for 
precisely this reason that the <a href="http://mozillascience.org/" title="Mozilla Science 
Lab" target="_blank">Mozilla Science Lab</a> - whose mission is to help researchers use 
the open web to shape scienceâ€™s future - is now the organisational home for 
<a href="http://software-carpentry.org/" title="Software Carpentry" target="_blank">
Software Carpentry</a>. They recognise that in order for these tools and practices to 
make it out of buzz word editorials and into the default workflow of everyday scientists, 
the entire profession needs to upskill. Graduates of a two-day Software Carpentry 
bootcamp, whether they immediately realise it or not, have all the basic skills and 
knowledge necessary to transition to a research workflow that looks something more like 
this:
<ul>
    <li>The data that the scientist collects is stored in an open access repository like 
        <a href="http://figshare.com/" title="figshare" target="_blank">figshare</a> or 
        <a href="http://datadryad.org/" title="Dryad" target="_blank">Dryad</a> as soon 
        as it's collected, and given its own DOI.</li>
    <li>The scientist creates a new 
        <a href="http://drclimate.wordpress.com/2012/11/16/version-control/" title="
        Version control" target="_blank">version control</a> repository on 
        <a href="https://github.com/" title="GitHub" target="_blank">GitHub</a> to hold 
        her work.</li>
    <li>As she does her analysis, she pushes changes to her scripts (and possibly some 
        output files) to that repository. She also uses the repository for her paper; 
        that repository is then the hub for collaboration with her colleagues.</li>
    <li>She regularly attends her local 
        <a href="http://conference.scipy.org/index.html" title="SciPy conference 
        home" target="_blank">SciPy conference</a> and is on the mailing lists of her 
        favourite Python packages, which means she has a large support network. She is 
        also using <a href="http://arxiv.org/abs/1210.0530" title="Best practices for 
        scientific computing" target="_blank">best practices</a> like 
        <a href="http://drclimate.wordpress.com/2013/10/10/testing-your-code/" title="
        Testing your code" target="_blank">unit testing</a> and defensive programming, 
        which gives her confidence that her results are reliable.</li>
    <li>When she's happy with the state of her paper, she posts a version to 
        <a href="http://arxiv.org/" title="arXiv" target="_blank">arXiv</a> or some other 
        preprint server to invite feedback from peers.</li>
    <li>Based on that feedback, she may post several revisions before finally submitting 
        her paper to a journal.</li>
    <li>The published paper includes links to her preprint and to her code and data 
        repositories, which makes it much easier for other scientists to use her work as 
        starting point for their own research.</li>
</ul>